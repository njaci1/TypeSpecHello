import { DiagnosticHandler } from "./diagnostics.js";
import { SourceFile, TextRange } from "./types.js";
export declare enum Token {
    None = 0,
    Invalid = 1,
    EndOfFile = 2,
    Identifier = 3,
    NumericLiteral = 4,
    StringLiteral = 5,
    SingleLineComment = 6,
    MultiLineComment = 7,
    NewLine = 8,
    Whitespace = 9,
    ConflictMarker = 10,
    DocText = 11,
    DocCodeSpan = 12,
    DocCodeFenceDelimiter = 13,
    OpenBrace = 14,
    CloseBrace = 15,
    OpenParen = 16,
    CloseParen = 17,
    OpenBracket = 18,
    CloseBracket = 19,
    Dot = 20,
    Ellipsis = 21,
    Semicolon = 22,
    Comma = 23,
    LessThan = 24,
    GreaterThan = 25,
    Equals = 26,
    Ampersand = 27,
    Bar = 28,
    Question = 29,
    Colon = 30,
    ColonColon = 31,
    At = 32,
    AtAt = 33,
    Hash = 34,
    Star = 35,
    ForwardSlash = 36,
    Plus = 37,
    Hyphen = 38,
    Exclamation = 39,
    LessThanEquals = 40,
    GreaterThanEquals = 41,
    AmpsersandAmpersand = 42,
    BarBar = 43,
    EqualsEquals = 44,
    ExclamationEquals = 45,
    EqualsGreaterThan = 46,
    ImportKeyword = 47,
    ModelKeyword = 48,
    ScalarKeyword = 49,
    NamespaceKeyword = 50,
    UsingKeyword = 51,
    OpKeyword = 52,
    EnumKeyword = 53,
    AliasKeyword = 54,
    IsKeyword = 55,
    InterfaceKeyword = 56,
    UnionKeyword = 57,
    ProjectionKeyword = 58,
    ElseKeyword = 59,
    IfKeyword = 60,
    DecKeyword = 61,
    FnKeyword = 62,
    ExternKeyword = 63,
    ExtendsKeyword = 64,
    TrueKeyword = 65,
    FalseKeyword = 66,
    ReturnKeyword = 67,
    VoidKeyword = 68,
    NeverKeyword = 69,
    UnknownKeyword = 70
}
export type DocToken = Token.NewLine | Token.Whitespace | Token.ConflictMarker | Token.Star | Token.At | Token.CloseBrace | Token.Identifier | Token.DocText | Token.DocCodeSpan | Token.DocCodeFenceDelimiter | Token.EndOfFile;
export interface Scanner {
    /** The source code being scanned. */
    readonly file: SourceFile;
    /** The offset in UTF-16 code units to the current position at the start of the next token. */
    readonly position: number;
    /** The current token */
    readonly token: Token;
    /** The offset in UTF-16 code units to the start of the current token. */
    readonly tokenPosition: number;
    /** The flags on the current token. */
    readonly tokenFlags: TokenFlags;
    /** Advance one token. */
    scan(): Token;
    /** Advance one token inside DocComment. Use inside {@link scanRange} callback over DocComment range. */
    scanDoc(): DocToken;
    /** Reset the scanner to the given start and end positions, invoke the callback, and then restore scanner state. */
    scanRange<T>(range: TextRange, callback: () => T): T;
    /** Determine if the scanner has reached the end of the input. */
    eof(): boolean;
    /** The exact spelling of the current token. */
    getTokenText(): string;
    /**
     * The value of the current token.
     *
     * String literals are escaped and unquoted, identifiers are normalized,
     * and all other tokens return their exact spelling sames as
     * getTokenText().
     */
    getTokenValue(): string;
}
export declare enum TokenFlags {
    None = 0,
    Escaped = 1,
    TripleQuoted = 2,
    Unterminated = 4,
    NonAscii = 8,
    DocComment = 16,
    Backticked = 32
}
export declare function isTrivia(token: Token): boolean;
export declare function isComment(token: Token): boolean;
export declare function isKeyword(token: Token): boolean;
export declare function isPunctuation(token: Token): boolean;
export declare function isModifier(token: Token): boolean;
export declare function isStatementKeyword(token: Token): boolean;
export declare function createScanner(source: string | SourceFile, diagnosticHandler: DiagnosticHandler): Scanner;
export declare function skipTrivia(input: string, position: number, endPosition?: number): number;
export declare function skipWhiteSpace(input: string, position: number, endPosition?: number): number;
//# sourceMappingURL=scanner.d.ts.map